{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [14:37:46] Enabling RDKit 2019.09.3 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import math\n",
    "import scipy.io\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "\n",
    "from torch_sparse import coalesce\n",
    "from torch_scatter import scatter_add\n",
    "\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.data import InMemoryDataset, download_url, extract_zip, Data\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.utils import remove_self_loops\n",
    "from torch_geometric.utils import add_remaining_self_loops\n",
    "from torch_geometric.utils import scatter_\n",
    "\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit import rdBase\n",
    "from rdkit.Chem.rdchem import HybridizationType\n",
    "from rdkit import RDConfig\n",
    "from rdkit.Chem import ChemicalFeatures\n",
    "from rdkit.Chem.rdchem import BondType as BT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training을 위한 hyperparameter 설정\n",
    "target = 0\n",
    "dim = 64\n",
    "batch_size = 128\n",
    "lr = 0.01\n",
    "epochs = 300\n",
    "weight_decay = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QM9 Dataset\n",
    "class QM9(InMemoryDataset):\n",
    "    # Dataset 처리를 위한 variable 설정\n",
    "    url = 'https://s3-us-west-1.amazonaws.com/deepchem.io/datasets/molnet_publish/qm9.zip'\n",
    "    types = {'H': 0, 'C': 1, 'N': 2, 'O': 3, 'F': 4}\n",
    "    bond_types = {BT.SINGLE: 0, BT.DOUBLE: 1, BT.TRIPLE: 2, BT.AROMATIC: 3}\n",
    "    fdef_name = osp.join(RDConfig.RDDataDir, 'BaseFeatures.fdef')\n",
    "    factory = ChemicalFeatures.BuildFeatureFactory(fdef_name)\n",
    "    \n",
    "    # 초기화 함수\n",
    "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
    "        super(QM9, self).__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['gdb9.sdf', 'gdb9.sdf.csv']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return 'data.pt'\n",
    "    \n",
    "    # url을 통해 qm9 dataset을 다운\n",
    "    def download(self):\n",
    "        url = self.processed_url if rdkit is None else self.url\n",
    "        file_path = download_url(url, self.raw_dir)\n",
    "        extract_zip(file_path, self.raw_dir)\n",
    "        os.unlink(file_path)\n",
    "    \n",
    "    # node feature matrix => x 구성\n",
    "    @staticmethod\n",
    "    def get_atom_features(self, atoms, mol_feats):\n",
    "        type_idx = []\n",
    "        atomic_number = []\n",
    "        acceptor = []\n",
    "        donor = []\n",
    "        aromatic = []\n",
    "        sp, sp2, sp3 = [], [], []\n",
    "        num_hs = []\n",
    "        for atom in atoms:\n",
    "            type_idx.append(self.types[atom.GetSymbol()])\n",
    "            atomic_number.append(atom.GetAtomicNum())\n",
    "            donor.append(0)\n",
    "            acceptor.append(0)\n",
    "            aromatic.append(1 if atom.GetIsAromatic() else 0)\n",
    "            hybridization = atom.GetHybridization()\n",
    "            sp.append(1 if hybridization == HybridizationType.SP else 0)\n",
    "            sp2.append(1 if hybridization == HybridizationType.SP2 else 0)\n",
    "            sp3.append(1 if hybridization == HybridizationType.SP3 else 0)\n",
    "            num_hs.append(atom.GetTotalNumHs(includeNeighbors=True))\n",
    "        \n",
    "        for j in range(len(mol_feats)):\n",
    "            if mol_feats[j].GetFamily() == 'Donor':\n",
    "                node_list = mol_feats[j].GetAtomIds()\n",
    "                for k in node_list:\n",
    "                    donor[k] = 1\n",
    "            elif mol_feats[j].GetFamily() == 'Acceptor':\n",
    "                node_list = mol_feats[j].GetAtomIds()\n",
    "                for k in node_list:\n",
    "                    acceptor[k] = 1\n",
    "\n",
    "        x1 = F.one_hot(torch.tensor(type_idx), num_classes=len(self.types))\n",
    "        x2 = torch.tensor([atomic_number, acceptor, donor, aromatic, sp, sp2, sp3, num_hs], dtype=torch.float).t().contiguous()\n",
    "        x = torch.cat([x1.to(torch.float), x2], dim=-1)\n",
    "        return x\n",
    "    \n",
    "    # adjacency matrix와 edge feature matrix 구성 (sparse)\n",
    "    @staticmethod\n",
    "    def get_bind_pair(self, bonds):\n",
    "        row, col, bond_idx = [], [], []\n",
    "        for bond in bonds:\n",
    "            # 양방향 연결임을 고려\n",
    "            start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "            row += [start, end]\n",
    "            col += [end, start]\n",
    "            bond_idx += 2 * [self.bond_types[bond.GetBondType()]]\n",
    "\n",
    "        edge_index = torch.tensor([row, col], dtype=torch.long)\n",
    "        edge_attr = F.one_hot(torch.tensor(bond_idx), num_classes=len(self.bond_types)).to(torch.float)\n",
    "\n",
    "        return edge_index, edge_attr\n",
    "    \n",
    "    # molecular data를 graph data로 변환\n",
    "    @staticmethod\n",
    "    def mol2vec(self, mol):\n",
    "        atoms = mol.GetAtoms()\n",
    "        bonds = mol.GetBonds()\n",
    "        edge_index, edge_attr = self.get_bind_pair(self, bonds)\n",
    "\n",
    "        x = self.get_atom_features(self, atoms, self.factory.GetFeaturesForMol(mol))\n",
    "\n",
    "        return edge_index, edge_attr, x\n",
    "    \n",
    "    # dataset 구성\n",
    "    def process(self):\n",
    "        with open(self.raw_paths[1], 'r') as f:\n",
    "            target = f.read().split('\\n')[1:-1]\n",
    "            target = [[float(x) for x in line.split(',')[4:20]]\n",
    "                      for line in target]\n",
    "            target = torch.tensor(target, dtype=torch.float)\n",
    "        \n",
    "        data_list = []\n",
    "        suppl = Chem.SDMolSupplier(self.raw_paths[0], removeHs=False)\n",
    "        for i, mol in enumerate(suppl):\n",
    "            if mol is None: continue\n",
    "            \n",
    "            text = suppl.GetItemText(i)\n",
    "            N = mol.GetNumAtoms()\n",
    "            \n",
    "            # get pos\n",
    "            pos = text.split('\\n')[4:4 + N]\n",
    "            pos = [[float(x) for x in line.split()[:3]] for line in pos]\n",
    "            pos = torch.tensor(pos, dtype=torch.float)\n",
    "            \n",
    "            # get graph data => edge_index, edge_attr, x\n",
    "            edge_index, edge_attr, x = self.mol2vec(self, mol)\n",
    "            edge_index, edge_attr = coalesce(edge_index, edge_attr, N, N)\n",
    "            \n",
    "            # get target data => y\n",
    "            y = target[i].unsqueeze(0)\n",
    "            \n",
    "            # get name\n",
    "            name = mol.GetProp('_Name')\n",
    "            \n",
    "            # data 구성\n",
    "            data = Data(x=x, pos=pos, edge_index=edge_index, edge_attr=edge_attr, y=y, name=name)\n",
    "\n",
    "            if self.pre_filter is not None and not self.pre_filter(data): continue\n",
    "            if self.pre_transform is not None: data = self.pre_transform(data)\n",
    "\n",
    "            data_list.append(data)\n",
    "\n",
    "        torch.save(self.collate(data_list), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniform xaiver weight initializer\n",
    "def glorot(tensor):\n",
    "    if tensor is not None:\n",
    "        stdv = math.sqrt(6.0 / (tensor.size(-2) + tensor.size(-1)))\n",
    "        tensor.data.uniform_(-stdv, stdv)\n",
    "\n",
    "def zeros(tensor):\n",
    "    if tensor is not None:\n",
    "        tensor.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNConvLayer(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, improved=False, cached=False,\n",
    "                 bias=True, normalize=True, single_param=False, **kwargs):\n",
    "        super(GCNConvLayer, self).__init__(aggr='add', **kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.improved = improved\n",
    "        self.cached = cached\n",
    "        self.normalize = normalize\n",
    "        self.single_param = single_param\n",
    "\n",
    "        self.weight = Parameter(torch.Tensor(in_channels, out_channels))\n",
    "\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        glorot(self.weight)\n",
    "        zeros(self.bias)\n",
    "        self.cached_result = None\n",
    "        self.cached_num_edges = None\n",
    "    \n",
    "    # Equation 7\n",
    "    @staticmethod\n",
    "    def single_parameter(edge_index, num_nodes, edge_weight=None, improved=False,\n",
    "             dtype=None):\n",
    "        if edge_weight is None:\n",
    "            edge_weight = torch.ones((edge_index.size(1), ), dtype=dtype,\n",
    "                                     device=edge_index.device)\n",
    "        row, col = edge_index\n",
    "        deg = scatter_add(edge_weight, row, dim=0, dim_size=num_nodes)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        \n",
    "        edge_weight = deg_inv_sqrt[row] * edge_weight * deg_inv_sqrt[col]\n",
    "        \n",
    "        fill_value = 1 if not improved else 2\n",
    "        edge_index, edge_weight = add_remaining_self_loops(\n",
    "            edge_index, edge_weight, fill_value, num_nodes)\n",
    "        \n",
    "        return edge_index, edge_weight\n",
    "    \n",
    "    # Equation 8\n",
    "    @staticmethod\n",
    "    def norm(edge_index, num_nodes, edge_weight=None, improved=False,\n",
    "             dtype=None):\n",
    "        if edge_weight is None:\n",
    "            edge_weight = torch.ones((edge_index.size(1), ), dtype=dtype,\n",
    "                                     device=edge_index.device)\n",
    "\n",
    "        fill_value = 1 if not improved else 2\n",
    "        edge_index, edge_weight = add_remaining_self_loops(\n",
    "            edge_index, edge_weight, fill_value, num_nodes)\n",
    "\n",
    "        row, col = edge_index\n",
    "        deg = scatter_add(edge_weight, row, dim=0, dim_size=num_nodes)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "\n",
    "        return edge_index, deg_inv_sqrt[row] * edge_weight * deg_inv_sqrt[col]\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        x = torch.matmul(x, self.weight)\n",
    "\n",
    "        if self.cached and self.cached_result is not None:\n",
    "            if edge_index.size(1) != self.cached_num_edges:\n",
    "                raise RuntimeError(\n",
    "                    'Cached {} number of edges, but found {}. Please '\n",
    "                    'disable the caching behavior of this layer by removing '\n",
    "                    'the `cached=True` argument in its constructor.'.format(\n",
    "                        self.cached_num_edges, edge_index.size(1)))\n",
    "\n",
    "        if not self.cached or self.cached_result is None:\n",
    "            self.cached_num_edges = edge_index.size(1)\n",
    "            if self.normalize:\n",
    "                edge_index, norm = self.norm(edge_index, x.size(0),\n",
    "                                             edge_weight, self.improved,\n",
    "                                             x.dtype)\n",
    "            elif self.single_param:\n",
    "                edge_index, norm = self.single_parameter(edge_index, x.size(0),\n",
    "                                             edge_weight, self.improved,\n",
    "                                             x.dtype)\n",
    "            else:\n",
    "                norm = edge_weight\n",
    "                \n",
    "            self.cached_result = edge_index, norm\n",
    "\n",
    "        edge_index, norm = self.cached_result\n",
    "\n",
    "        return self.propagate(edge_index, x=x, norm=norm)\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        return norm.view(-1, 1) * x_j if norm is not None else x_j\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        if self.bias is not None:\n",
    "            aggr_out = aggr_out + self.bias\n",
    "        return aggr_out\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels,\n",
    "                                   self.out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average node features\n",
    "def global_mean_pool(x, batch, size=None):\n",
    "    size = batch.max().item() + 1 if size is None else size\n",
    "    return scatter_('mean', x, batch, dim=0, dim_size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Neural Network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConvLayer(dataset.num_features, dim * 2, cached=False,\n",
    "                            normalize=True, single_param=False)\n",
    "        self.conv2 = GCNConvLayer(dim * 2, dim, cached=False,\n",
    "                            normalize=True, single_param=False)\n",
    "        self.lin1 = nn.Linear(dim, 1)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        out = F.relu(self.conv1(x, edge_index))\n",
    "        out = F.dropout(out, training=self.training)\n",
    "        out = self.conv2(out, edge_index)\n",
    "        out = global_mean_pool(out, data.batch)\n",
    "        out = self.lin1(out)\n",
    "        return out.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTransform(object):\n",
    "    def __call__(self, data):\n",
    "        # Specify target.\n",
    "        data.y = data.y[:, target]\n",
    "        return data\n",
    "\n",
    "\n",
    "class Complete(object):\n",
    "    def __call__(self, data):\n",
    "        device = data.edge_index.device\n",
    "\n",
    "        row = torch.arange(data.num_nodes, dtype=torch.long, device=device)\n",
    "        col = torch.arange(data.num_nodes, dtype=torch.long, device=device)\n",
    "\n",
    "        row = row.view(-1, 1).repeat(1, data.num_nodes).view(-1)\n",
    "        col = col.repeat(data.num_nodes)\n",
    "        edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "        edge_attr = None\n",
    "        if data.edge_attr is not None:\n",
    "            idx = data.edge_index[0] * data.num_nodes + data.edge_index[1]\n",
    "            size = list(data.edge_attr.size())\n",
    "            size[0] = data.num_nodes * data.num_nodes\n",
    "            edge_attr = data.edge_attr.new_zeros(size)\n",
    "            edge_attr[idx] = data.edge_attr\n",
    "\n",
    "        edge_index, edge_attr = remove_self_loops(edge_index, edge_attr)\n",
    "        data.edge_attr = edge_attr\n",
    "        data.edge_index = edge_index\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = osp.join(osp.dirname(osp.realpath('')), '..', 'data', 'QM9')\n",
    "transform = T.Compose([MyTransform(), Complete(), T.Distance(norm=False)])\n",
    "dataset = QM9(path, transform=transform).shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize targets to mean = 0 and std = 1.\n",
    "mean = dataset.data.y.mean(dim=0, keepdim=True)\n",
    "std = dataset.data.y.std(dim=0, keepdim=True)\n",
    "dataset.data.y = (dataset.data.y - mean) / std\n",
    "mean, std = mean[:, target].item(), std[:, target].item()\n",
    "\n",
    "# Split datasets. (cross validation)\n",
    "test_dataset = dataset[:10000]\n",
    "val_dataset = dataset[10000:20000]\n",
    "train_dataset = dataset[20000:]\n",
    "\n",
    "# Data Loader 구성\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = dataset[0].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model과 optimizer 초기화\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = F.mse_loss(model(data), data.y)\n",
    "        loss.backward()\n",
    "        loss_all += loss.item() * data.num_graphs\n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_loader.dataset)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    error = 0\n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        error += (model(data) * std - data.y * std).abs().sum().item()  # MAE\n",
    "    return error / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.6967202, Validation MAE: 0.8832881, Test MAE: 0.8829607\n",
      "Epoch: 002, Loss: 0.6569940, Validation MAE: 0.8855286, Test MAE: 0.8829607\n",
      "Epoch: 003, Loss: 0.6504361, Validation MAE: 0.8596573, Test MAE: 0.8557926\n",
      "Epoch: 004, Loss: 0.6488518, Validation MAE: 0.8699367, Test MAE: 0.8557926\n",
      "Epoch: 005, Loss: 0.6462197, Validation MAE: 0.8593770, Test MAE: 0.8622034\n",
      "Epoch: 006, Loss: 0.6436653, Validation MAE: 0.8694602, Test MAE: 0.8622034\n",
      "Epoch: 007, Loss: 0.6423671, Validation MAE: 0.8707799, Test MAE: 0.8622034\n",
      "Epoch: 008, Loss: 0.6421476, Validation MAE: 0.8775520, Test MAE: 0.8622034\n",
      "Epoch: 009, Loss: 0.6386914, Validation MAE: 0.8555285, Test MAE: 0.8539425\n",
      "Epoch: 010, Loss: 0.6405800, Validation MAE: 0.8521609, Test MAE: 0.8515646\n",
      "Epoch: 011, Loss: 0.6414883, Validation MAE: 0.8628033, Test MAE: 0.8515646\n",
      "Epoch: 012, Loss: 0.6382103, Validation MAE: 0.8584975, Test MAE: 0.8515646\n",
      "Epoch: 013, Loss: 0.6390986, Validation MAE: 0.9089658, Test MAE: 0.8515646\n",
      "Epoch: 014, Loss: 0.6415276, Validation MAE: 0.9165382, Test MAE: 0.8515646\n",
      "Epoch: 015, Loss: 0.6455141, Validation MAE: 0.8753576, Test MAE: 0.8515646\n",
      "Epoch: 016, Loss: 0.6393787, Validation MAE: 0.8573469, Test MAE: 0.8515646\n",
      "Epoch: 017, Loss: 0.6387670, Validation MAE: 0.8520817, Test MAE: 0.8537460\n",
      "Epoch: 018, Loss: 0.6378268, Validation MAE: 0.8663734, Test MAE: 0.8537460\n",
      "Epoch: 019, Loss: 0.6371886, Validation MAE: 0.8606952, Test MAE: 0.8537460\n",
      "Epoch: 020, Loss: 0.6394407, Validation MAE: 0.8514304, Test MAE: 0.8490588\n",
      "Epoch: 021, Loss: 0.6368737, Validation MAE: 0.8588333, Test MAE: 0.8490588\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-842f209c643a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbest_val_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mval_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-c7a6d7686ef5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mloss_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch_geometric/data/in_memory_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch_geometric/transforms/compose.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-5e3eed447691>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0medge_attr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_self_loops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch_geometric/utils/loop.py\u001b[0m in \u001b[0;36mremove_self_loops\u001b[0;34m(edge_index, edge_attr)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0medge_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_attr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0medge_attr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_val_error = None\n",
    "for epoch in range(epochs):\n",
    "    loss = train(epoch)\n",
    "    val_error = test(val_loader)\n",
    "\n",
    "    if best_val_error is None or val_error <= best_val_error:\n",
    "        test_error = test(test_loader)\n",
    "        best_val_error = val_error\n",
    "\n",
    "    print('Epoch: {:03d}, Loss: {:.7f}, Validation MAE: {:.7f}, Test MAE: {:.7f}'.format(epoch + 1, loss, val_error, test_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_p36]",
   "language": "python",
   "name": "conda-env-pytorch_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
